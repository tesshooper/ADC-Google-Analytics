---
title: "Google Analytics User Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Google Analytics Categorization**
Categorizing ADC site page URL's to more easily analyze user engagement. 

<br>

```{r Load Packages, include=FALSE, echo=FALSE, warning = FALSE}

library(tidyverse)
library(tidyr)
library(dplyr)
library(lubridate)
library(knitr)
library(kableExtra)
library(tidytext)
library(stringr)
library(tm)
library(ggplot2)
library(treemap)
library(plotly)
library(plotrix)
library(d3treeR)
library(htmlwidgets)
library(circlize)
library(DT)
library(xlsx)

## to install d3treeR, use devtools::install_github("timelyportfolio/d3treeR") 
```



```{r Load Data, message = FALSE, warning = FALSE, echo = FALSE, include = FALSE}

# Load in Most Visited Pages data obtained from Google Analytics from February 20, 2016 to December 11, 2020

user_report_raw <- read.csv("/home/t_hooper/ADC-Google-Analytics/User_Report_Feb2016-Dec2020.csv")

# Report includes Page URL, Users, Sessions, User % of Total, Pageviews, Unique Pageviews, Entrances, and Bounce Rate

## **** IMPORTANT **** Data is currently set to be viewed as Pages with the most USERS who visit that page. You can re-order based on Pageviews or Unique Pageviews depending on how you want to visualize the data. 


## FOR TEST ## - take top 30 rows of users_report_raw:
top_30_users <- head(user_report_raw, n = 30)

```

### **Google Analytics Definitions**
**Page:** The page shows the part of the URL after your domain name (path) when someone has viewed content on your website. For example, if someone views https://www.example.com/contact then /contact will be reported as the page inside the Behavior reports.  
**User:** An individual visitor to the site (tracked using browser cookies)  
**Sessions:** A single visit to the website, consisting of one or more pageviews, and any other interactions (The default session timeout is 30 minutes)  
**User % of Total:** Users displayed as a percentage of the Total Users during the report period  
**Pageviews:** The number of times users view a page that has the Google Analytics tracking code inserted. This covers all page views; so if a user refreshes the page, or navigates away from the page and returns, these are all counted as additional page views.  
**Unique Pageviews:** The unique pageview is the count of all the times the page was viewed in an individual session as a single event. If a user viewed the page once in their visit or five times, the number of unique pageviews will be counted as just one  
**Entrances:** Entrance represents the number of visits that started on a specific web page or group of web pages. I.e. the first page that someone views during a session  
**Bounce Rate:** The Bounce Rate is Bounce measured in percentage. It represents the number of visits when users leave your site after just one page view, regardless of how long they stayed on that page. (Total Bounces divided by total visits)  

<br>
<br>

### **Categorization Function**
We will use the code and function below to categorize the Google Analytics dataset. The function takes messy character data within a dataframe and categorizes it based on a set of search string criteria. The inputs are the data frame, the column name of the messy data, a list of search strings, a list of category names (these have to be correlated), and you have the option of naming the new column. <br> <br>

It is important to note that the order of the search strings matters for strings that are repeats -- i.e. "catalog" and "catalog/submit" will be written over so you must identify the longer string first (i.e. catalog/submit). Additionally, make sure the order of the categories list correlates with the order of the search strings. <br> 
*Source: https://github.com/lenwood*

<br>
<br>


### **Identify Search Strings and Category Names**
```{r Identify Search Strings and Categories, eval = FALSE}

# List of search strings -- note that the longer search strings are identified first 
search <- c("news", "portals", "about","catalogprofile", "catalogsubmit", "catalog", "training", "team", "home", "view", "submit", "profile")

# List of categories
categories <- c("News", "Portals", "About", "Summary", "Submit", "Cathome", "Training", "Team", "Home", "Dataset", "WhoMustSub", "Summary")

```
<br>


### **Create Categorization Function**
```{r Create Function, eval = FALSE}

# Quickly categorize a data frame with a column of messy character strings. 

# Replace "df" with your messy dataframe.

categorizeDF <- function(df, searchColName, searchList, catList, newColName="Category") {
  # create empty data frame to hold categories
  catDF <- data.frame(matrix(ncol=ncol(df), nrow=0))
  colnames(catDF) <- paste0(names(df))

  # add sequence so original order can be restored
  df$sequence <- seq(nrow(df))

  # iterate through the strings
  for (i in seq_along(searchList)) {
    rownames(df) <- NULL
    index <- grep(searchList[i], df[,which(colnames(df) == searchColName)], ignore.case=TRUE)
    tempDF <- df[index,]
    tempDF$newCol <- catList[i]
    catDF <- rbind(catDF, tempDF)
    df <- df[-index,]
  }

  # OTHER category for unmatched rows
  if (nrow(df) > 0) {
    df$newCol <- "OTHER"
    catDF <- rbind(catDF, df)
  }

  # return to the original order & remove the sequence data
  catDF <- catDF[order(catDF$sequence),]
  catDF$sequence <- NULL

  # remove row names
  rownames(catDF) <- NULL

  # set Category type to factor
  catDF$newCol <- as.factor(catDF$newCol)

  # rename the new column
  colnames(catDF)[which(colnames(catDF) == "newCol")] <- newColName
  catDF
}

```
<br>

### **Call Function and Categorize Data**
```{r Call Function and Categorize, eval = FALSE}

# Replace "df" with messy dataframe

# Identify which column you want to categorize -- in our case with Google Analytics, we will be categorizing the "Page" column that contains messy URL strings. Additionally, you can name the new column that contains the categories (e.g. "Category").

sorted <- categorizeDF(df, "column name with messy data", search, categories, "new category column name")

```
<br>
<br>

### **Test Run of Categorization with Small Subset of Data**
```{r TEST Clean Pathways, warning = FALSE, message = FALSE}


###### TEST DATASET ######


# Remove backslashes and other symbols from Page column (includes hyphens and periods). **** Not sure if this is necessary. Am trying to differentiate the single "/" as the ADC Homepage, and make it easier to identify search terms for the function below. 
test_users_clean <- top_30_users %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .)))


# Rename home page as "home" in dataframe **NOTE that for this particular dataset the "Home" page is the top viewed page and so I put in [1]. If it is not the top viewed page you will need to determine which row the homepage is and put that row number in the brackets. *** Is there a better way to do this?? ***

test_users_clean$Page[1] <- "home"


```
<br>

```{r TEST Create Function, warning = FALSE, message = FALSE}

### Categorize the page URLS in the Page column into larger categories using a function ###

## Create a list of search strings to sort through pages and a list of categories (these must be correlated) **Order matters for strings that are repeats -- i.e. "catalog" and "catalog/submit" will be written over so you must identify the longer string first (i.e. catalog/submit). 

# List of search strings
search <- c("news", "portals", "about","catalogprofile", "catalogsubmit", "catalog", "training", "team", "home", "view", "submit", "profile")

# List of categories
categories <- c("News", "Portals", "About", "Summary", "Submit", "Cathome", "Training", "Team", "Home", "Dataset", "WhoMustSub", "Summary")



## Create function [below] to categorize the messy "Page" column of the raw data frame. 
# This function takes looks at a data frame column of messy character (or factorial) data, and produces a new column of categorized data. The inputs are the data frame, the column name of the messy data, a list of search strings, a list of category names (these two have to be correlated), and you have the option of naming the new column.


# Function:
categorizeDF <- function(test_users_clean, searchColName, searchList, catList, newColName="Category") {
  # create empty data frame to hold categories
  catDF <- data.frame(matrix(ncol=ncol(test_users_clean), nrow=0))
  colnames(catDF) <- paste0(names(test_users_clean))

  # add sequence so original order can be restored
  test_users_clean$sequence <- seq(nrow(test_users_clean))

  # iterate through the strings
  for (i in seq_along(searchList)) {
    rownames(test_users_clean) <- NULL
    index <- grep(searchList[i], test_users_clean[,which(colnames(test_users_clean) == searchColName)], ignore.case=TRUE)
    tempDF <- test_users_clean[index,]
    tempDF$newCol <- catList[i]
    catDF <- rbind(catDF, tempDF)
    test_users_clean <- test_users_clean[-index,]
  }

  # OTHER category for unmatched rows
  if (nrow(test_users_clean) > 0) {
    test_users_clean$newCol <- "OTHER"
    catDF <- rbind(catDF, test_users_clean)
  }

  # return to the original order & remove the sequence data
  catDF <- catDF[order(catDF$sequence),]
  catDF$sequence <- NULL

  # remove row names
  rownames(catDF) <- NULL

  # set Category type to factor
  catDF$newCol <- as.factor(catDF$newCol)

  # rename the new column
  colnames(catDF)[which(colnames(catDF) == "newCol")] <- newColName
  catDF
}



```
<br>

```{r TEST Call function and categorize, warning = FALSE, message = FALSE}

# Call the function and create new data frame - using the raw data frame, the messy column you want to sort, the search and category lists, and name of the new column

sortedDF <- categorizeDF(test_users_clean, "Page", search, categories, "Category")


```
<br>

```{r View Categorized Dataframe, warning = FALSE, message = FALSE}

knitr::kable(sortedDF, format = "html")

```


<br>
<br>


```{r 2016-2020 Dataset - Clean Pathways, warning = FALSE, message = FALSE, echo = FALSE}

#### FULL DATASET February 20th 2016 - December 11th 2020 ####


# Remove backslashes and other symbols from Page column (includes hyphens and periods). **** Not sure if this is necessary. Am trying to differentiate the single "/" as the ADC Homepage, and make it easier to identify search terms for the function below. 
total_users_clean <- user_report_raw %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .)))


# Rename home page as "home" in dataframe **NOTE that for this particular dataset the "Home" page is the top viewed page and so I put in [1]. If it is not the top viewed page you will need to determine which row the homepage is and put that row number in the brackets. *** Is there a better way to do this?? ***

total_users_clean$Page[1] <- "home"

```

```{r 2016-2020 Dataset - Create Function, message = FALSE, warning = FALSE, echo = FALSE}

### Categorize the page URLS in the Page column into larger categories using a function ###

## Create a list of search strings to sort through pages and a list of categories (these must be correlated) **Order matters for strings that are repeats, as the function will categorize in the order in which they are assigned(i.e. "catalog" and "catalog/submit" will be written over so you must identify the longer string first (i.e. catalog/submit) in the search list. 

# List of search strings
search <- c("news", "portals", "view", "about","catalogprofile", "catalogsubmit", "catalogshare", "catalog", "meetings", "team", "home", "submit", "profile", "qanda", "support" , "share", "publications", "dataplans", "history", "searchtips", "api", "projects", "webinar", "video", "mydata", "datapreservation", "knb", "plannedoutage", "proposal", "blog", "training", "datapage0", "page0", "data")

# List of categories
categories <- c("News", "Portals", "Dataset", "About", "Summary", "Submit", "Dataset", "Cathome", "Training", "Team", "Home",  "WhoMustSub", "Summary", "QA", "Support", "Dataset", "Publications", "DataPlans", "History", "SearchTips", "API", "Projects", "Webinar", "Webinar", "MyData", "DataPreservation", "KNB", "Outage", "Proposals", "Blog","Training", "Cathome", "Cathome", "Cathome")



## Create function [below] to categorize the messy "Page" column of the raw data frame. 
# This function takes looks at a data frame column of messy character (or factorial) data, and produces a new column of categorized data. The inputs are the data frame, the column name of the messy data, a list of search strings, a list of category names (these two have to be correlated), and you have the option of naming the new column.


# Function:
categorize_FULL_DF <- function(total_users_clean, searchColName, searchList, catList, newColName="Category") {
  # create empty data frame to hold categories
  catDF <- data.frame(matrix(ncol=ncol(total_users_clean), nrow=0))
  colnames(catDF) <- paste0(names(total_users_clean))

  # add sequence so original order can be restored
  total_users_clean$sequence <- seq(nrow(total_users_clean))

  # iterate through the strings
  for (i in seq_along(searchList)) {
    rownames(total_users_clean) <- NULL
    index <- grep(searchList[i], total_users_clean[,which(colnames(total_users_clean) == searchColName)], ignore.case=TRUE)
    tempDF <- total_users_clean[index,]
    tempDF$newCol <- catList[i]
    catDF <- rbind(catDF, tempDF)
    total_users_clean <- total_users_clean[-index,]
  }

  # OTHER category for unmatched rows
  if (nrow(total_users_clean) > 0) {
    total_users_clean$newCol <- "OTHER"
    catDF <- rbind(catDF, total_users_clean)
  }

  # return to the original order & remove the sequence data
  catDF <- catDF[order(catDF$sequence),]
  catDF$sequence <- NULL

  # remove row names
  rownames(catDF) <- NULL

  # set Category type to factor
  catDF$newCol <- as.factor(catDF$newCol)

  # rename the new column
  colnames(catDF)[which(colnames(catDF) == "Category")] <- newColName
  catDF
}


```

```{r 2016-2020 Dataset - Call Function and Categorize, echo = FALSE, message = FALSE, warning = FALSE}

# Call the function and create new data frame - using the raw data frame, the messy column you want to sort, the search and category lists, and name of the new column

full_sortedDF <- categorizeDF(total_users_clean, "Page", search, categories, "Category")



```

<br>
<br>

### **Visualizations for User Analysis**
```{r Load Annual Data, echo = FALSE, message = FALSE, warning = FALSE}

# Visualize changes in Users over time. In order to do this we need to load in annual datasets from Google Analytics (since the current data does not include datas)

# Load 2016 data
users_2016 <- read.csv("/home/t_hooper/ADC-Google-Analytics/2016_users_adc.csv")

# Load 2017 data
users_2017 <- read.csv("/home/t_hooper/ADC-Google-Analytics/2017_users_adc.csv")

# Load 2018 data
users_2018 <- read.csv("/home/t_hooper/ADC-Google-Analytics/2018_users_adc.csv")

# Load 2019 data
users_2019 <- read.csv("/home/t_hooper/ADC-Google-Analytics/2019_users_adc.csv")

# Load 2020 data
users_2020 <- read.csv("/home/t_hooper/ADC-Google-Analytics/2020_users_adc.csv")


```



```{r Annual Data - Clean Pathways and Add Year Column, echo = FALSE, warning = FALSE, message = FALSE}


# Remove backslashes and other symbols from Page column (includes hyphens and periods). **** Not sure if this is necessary. Am trying to differentiate the single "/" as the ADC Homepage, and make it easier to identify search terms for the function below. 
# We also want to add a column for YEAR

# 2016 Data
users_2016_clean <- users_2016 %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .))) 

users_2016_clean$Year <- c("2016")

# 2017 Data
users_2017_clean <- users_2017 %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .)))

users_2017_clean$Year <- c("2017")

# 2018 Data
users_2018_clean <- users_2018 %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .)))

users_2018_clean$Year <- c("2018")

# 2019 Data
users_2019_clean <- users_2019 %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .)))

users_2019_clean$Year <- c("2019")

# 2020 Data
users_2020_clean <- users_2020 %>%
  mutate_all(funs(gsub("[[:punct:]]", "", .)))

users_2020_clean$Year <- c("2020")

# Rename home page as "home" in dataframe **NOTE that for this particular dataset the "Home" page is the top viewed page and so I put in [1]. If it is not the top viewed page you will need to determine which row the homepage is and put that row number in the brackets. *** Is there a better way to do this?? ***


# 2016 Data
users_2016_clean$Page[1] <- "home"

# 2017 Data
users_2017_clean$Page[1] <- "home"

# 2018 Data
users_2018_clean$Page[1] <- "home"

# 2019 Data
users_2019_clean$Page[1] <- "home"

# 2020 Data
users_2020_clean$Page[1] <- "home"

```

```{r Combine Annual Dataframes, echo = FALSE, warning = FALSE, message = FALSE }

# Combine dataframes vertically using the rbind function

all_annual_users <- rbind(users_2016_clean, users_2017_clean, users_2018_clean, users_2019_clean, users_2020_clean)


```

```{r Create Categorization Function for Annual Dataset, echo = FALSE, message = FALSE, warning = FALSE}

### Categorize the page URLS in the Page column into larger categories using a function ###

## Create a list of search strings to sort through pages and a list of categories (these must be correlated) **Order matters for strings that are repeats, as the function will categorize in the order in which they are assigned(i.e. "catalog" and "catalog/submit" will be written over so you must identify the longer string first (i.e. catalog/submit) in the search list. 

# List of search strings
search <- c("news", "portals", "view", "about","catalogprofile", "catalogsubmit", "catalogshare", "catalog", "meetings", "team", "home", "submit", "profile", "qanda", "support" , "share", "publications", "dataplans", "history", "searchtips", "api", "projects", "webinar", "video", "mydata", "datapreservation", "knb", "plannedoutage", "proposal", "blog", "training", "datapage0", "page0")

# List of categories
categories <- c("News", "Portals", "Dataset", "About", "Summary", "Submit", "Dataset", "Cathome", "Training", "Team", "Home",  "WhoMustSub", "Summary", "QA", "Support", "Dataset", "Publications", "DataPlans", "History", "SearchTips", "API", "Projects", "Webinar", "Webinar", "MyData", "DataPreservation", "KNB", "Outage", "Proposals", "Blog","Training", "Cathome", "Cathome")



## Create function [below] to categorize the messy "Page" column of the raw data frame. 
# This function takes looks at a data frame column of messy character (or factorial) data, and produces a new column of categorized data. The inputs are the data frame, the column name of the messy data, a list of search strings, a list of category names (these two have to be correlated), and you have the option of naming the new column.


# Function:
categorize_ANNUAL_DF <- function(all_annual_users, searchColName, searchList, catList, newColName="Category") {
  # create empty data frame to hold categories
  catDF <- data.frame(matrix(ncol=ncol(all_annual_users), nrow=0))
  colnames(catDF) <- paste0(names(all_annual_users))

  # add sequence so original order can be restored
  all_annual_users$sequence <- seq(nrow(all_annual_users))

  # iterate through the strings
  for (i in seq_along(searchList)) {
    rownames(all_annual_users) <- NULL
    index <- grep(searchList[i], all_annual_users[,which(colnames(all_annual_users) == searchColName)], ignore.case=TRUE)
    tempDF <- all_annual_users[index,]
    tempDF$newCol <- catList[i]
    catDF <- rbind(catDF, tempDF)
    all_annual_users <- all_annual_users[-index,]
  }

  # OTHER category for unmatched rows
  if (nrow(all_annual_users) > 0) {
    all_annual_users$newCol <- "OTHER"
    catDF <- rbind(catDF, all_annual_users)
  }

  # return to the original order & remove the sequence data
  catDF <- catDF[order(catDF$sequence),]
  catDF$sequence <- NULL

  # remove row names
  rownames(catDF) <- NULL

  # set Category type to factor
  catDF$newCol <- as.factor(catDF$newCol)

  # rename the new column
  colnames(catDF)[which(colnames(catDF) == "Category")] <- newColName
  catDF
}

```

```{r Call Function to Categorize Annual Data, echo = FALSE, message = FALSE, warning = FALSE}

# Call the function and create new data frame - using the raw data frame, the messy column you want to sort, the search and category lists, and name of the new column

annual_sortedDF <- categorizeDF(all_annual_users, "Page", search, categories, "Category")


```



```{r Extract Sorted Individual Years Top 30, echo = FALSE, message = FALSE, warning = FALSE, include = FALSE, warning = FALSE, results = FALSE}

 
####### TEST FOR VISUALIZATION -- extract individual years and take top 30 pages ########


# Extract 2016 from categorized dataframe 
sorted_2016 <- annual_sortedDF[which(annual_sortedDF$Year == "2016"), c(1:10)] 

# Extract top 30 pages
top30_2016 <- head(sorted_2016, n = 30)

# Extract 2016 from categorized dataframe 
sorted_2017 <- annual_sortedDF[which(annual_sortedDF$Year == "2017"), c(1:10)] 

# Extract top 30 pages
top30_2017 <- head(sorted_2017, n = 30)

# Extract 2016 from categorized dataframe 
sorted_2018 <- annual_sortedDF[which(annual_sortedDF$Year == "2018"), c(1:10)] 

# Extract top 30 pages
top30_2018 <- head(sorted_2018, n = 30)

# Extract 2016 from categorized dataframe 
sorted_2019 <- annual_sortedDF[which(annual_sortedDF$Year == "2019"), c(1:10)] 

# Extract top 30 pages
top30_2019 <- head(sorted_2019, n = 30)

# Extract 2016 from categorized dataframe 
sorted_2020 <- annual_sortedDF[which(annual_sortedDF$Year == "2020"), c(1:10)] 

# Extract top 30 pages
top30_2020 <- head(sorted_2020, n = 30)


# Combine these dataframes
annual_top30_users <- rbind(top30_2016, top30_2017, top30_2018, top30_2019, top30_2020)

### Need to add up the Users/Categories for specific visualizations ###

############ Try bar plot for top 30 users for each year #############

### Create graphs for Users over time

## Summarize Users for each Year using tapply

# Needed to first transform Users and Year to numeric vectors
an_top30_users <- transform(annual_top30_users, Users = as.numeric(Users), 
               Year = as.numeric(Year))


# Summarize data
tapply(an_top30_users$Users, an_top30_users$Year, FUN=sum)

# 2016: 10,815
# 2017: 11,459
# 2018: 18,494
# 2019: 13,679
# 2020: 17,284


## Create simple bar graph of Users and Year

top30_users_barplot <- an_top30_users %>% 
  group_by(Year) %>% 
  summarise(Users = sum(Users)) %>% 
  ggplot(aes(x=Year, y=Users)) + 
  geom_bar(stat = "identity")
  
top30_users_barplot

```


```{r Create Custom Theme for Visualization, echo = FALSE, include = FALSE}

theme_ADC<- function() {
  theme_bw(base_size=12,base_family="Helvetica") %+replace%
    theme(
      plot.title=element_text(size=11, face="bold",margin=margin(10,0,10,0),color="#1D244F"),
      plot.subtitle = element_text(size=10,margin=margin(0,0,10,0),color="#1D244F"),
        axis.text.x = element_text(angle=50, size=8, vjust=0.5, color="#1D244F"),
        axis.text.y = element_text(size=8, color="#1D244F"),
        axis.title.x = element_text(color="#1D244F",vjust=-.5,size=10),
        axis.title.y = element_text(color="#1D244F",angle=90,vjust=.5,size=10),
        panel.background=element_rect(fill="white"),
        axis.line = element_line(color="#1D244F"),
      panel.grid.major = element_line(colour = "white", size = 0.2), 
    panel.grid.minor = element_line(colour = "white", size = 0.5),
    )
}


# Create ADC color palette

ADC_colors <- c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea")
sliceValues <- rep(10, 6)
pie3D(sliceValues[1:6],explode=0, theta=1.2, col=ADC_colors)
      
      
      
```
<br>

#### **Total Users Over Time**
##### *Remember that `Users` are all individual visitors to the site tracked by browser cookies. If a `User` visits the site multiple times with the same browser, they will not be counted twice.* 
<br>
```{r Bar Graph - Total Users Over Time, echo = FALSE, warning = FALSE, message = FALSE}


### Create bar graph for all Users over time

# Need to first transform columns to numeric vectors
annual_users <- transform(annual_sortedDF, Users = as.numeric(Users), 
               Year = as.character(Year),
               Sessions = as.numeric(Sessions),
               Pageviews = as.numeric(Pageviews), 
               Unique.Pageviews = as.numeric(Unique.Pageviews),
               Bounce.Rate = as.numeric(Bounce.Rate),
               Entrances = as.numeric(Entrances),
               Users...of.Total = as.numeric(Users...of.Total))


# Summarize data
tapply(annual_users$Users, annual_users$Year, FUN=sum)

# 2016: 23,772
# 2017: 32,205
# 2018: 48,337
# 2019: 31,187
# 2020: 60,330

###############################################################################

## Create simple bar graph of Users and Year

total_users_barplot <- annual_users %>% 
  group_by(Year) %>% 
  summarise(Users = sum(Users)) %>% 
  ggplot(aes(x=Year, y=Users)) + 
  scale_y_continuous(expand = c(0,0), limits = c(0, 70000)) +
  ggtitle("Total Users to the Arctic Data Center Site (2016 to 2020)") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_bar(fill = "#16897e", stat = "identity") 

#total_users_barplot

total_users_barplot <- total_users_barplot+theme_ADC() 
#total_users_barplot

### Make barplot interactive with hover text values using plotly
users_interactive <- ggplotly(total_users_barplot)  %>% 
  layout(hoverlabel=list(bgcolor="#b5e5ea"))
users_interactive

###############################################################################




```
<br>


#### **Tree Map for Total Users by Category and Year**

```{r Annual Tree Map - Users by Category/Year, echo = FALSE, message = FALSE, warning = FALSE, results = FALSE}

########### Create a treemap of total Users by Category within Year ##############

#### 2016 ####

## First transform to numeric/character vectors within each annual df 
sorted_2016 <- transform(sorted_2016, Category = as.character(Category),
                         Users = as.numeric(Users))

# Get totals for each category                          
cat_users_2016 <- sorted_2016 %>% 
  group_by(Category) %>% 
  summarise(Users = sum(Users))

# Add column for year
cat_users_2016$Year <- c("2016") 


#### 2017 ####

## First transform to numeric/character vectors within each annual df 
sorted_2017 <- transform(sorted_2017, Category = as.character(Category),
                         Users = as.numeric(Users))

# Get totals for each category                          
cat_users_2017 <- sorted_2017 %>% 
  group_by(Category) %>% 
  summarise(Users = sum(Users))

# Add column for year
cat_users_2017$Year <- c("2017") 


#### 2018 ####

## First transform to numeric/character vectors within each annual df 
sorted_2018 <- transform(sorted_2018, Category = as.character(Category),
                         Users = as.numeric(Users))

# Get totals for each category                          
cat_users_2018 <- sorted_2018 %>% 
  group_by(Category) %>% 
  summarise(Users = sum(Users))

# Add column for year
cat_users_2018$Year <- c("2018") 


#### 2019 ####

## First transform to numeric/character vectors within each annual df 
sorted_2019 <- transform(sorted_2019, Category = as.character(Category),
                         Users = as.numeric(Users))

# Get totals for each category                          
cat_users_2019 <- sorted_2019 %>% 
  group_by(Category) %>% 
  summarise(Users = sum(Users))

# Add column for year
cat_users_2019$Year <- c("2019") 



#### 2020 ####

## First transform to numeric/character vectors within each annual df 
sorted_2020 <- transform(sorted_2020, Category = as.character(Category),
                         Users = as.numeric(Users))

# Get totals for each category                          
cat_users_2020 <- sorted_2020 %>% 
  group_by(Category) %>% 
  summarise(Users = sum(Users))

# Add column for year
cat_users_2020$Year <- c("2020") 



#### Combine annual categories into one dataframe ####

annual_categories <- rbind(cat_users_2016, cat_users_2017, cat_users_2018, cat_users_2019, cat_users_2020)


cat_user_tree <- annual_categories %>% 
  treemap(index= c("Year", "Category"),
          vSize="Users",
          type="index",
          title = "Users to the Arctic Data Center Site by Category (2016 to 2020)",
          palette = ADC_colors,
          fontsize.title = 16,
          fontsize.labels = c(14, 12),
          fontface.labels = c(2, 1),
          bg.labels = "#CCCCCCDC"
            ) 
  
cat_user_tree 

### Make treemap interactive using d3treeR

# make it interactive ("rootname" becomes the title of the plot):
inter_cat_tree <- d3tree2(cat_user_tree,  rootname = "Users to the Arctic Data Center Site by Category (2016 to 2020)" )

inter_cat_tree


```

<br>

#### **Tree Map for Total Users 2016-2020**
```{r Tree Map All Time - Users per Category, echo = FALSE, message = FALSE, warning = FALSE }


########### Create a treemap of total Users by Category (2016-2020) ##############

## First transform to numeric/character vectors within each annual df 
annual_sortedDF <- transform(annual_sortedDF, Category = as.character(Category),
                         Users = as.numeric(Users))

# Get totals for each category                          
total_cat_users <- annual_sortedDF %>% 
  group_by(Category) %>% 
  summarise(Users = sum(Users))



### Create Tree Map ### 


total_cat_user_tree <- total_cat_users %>% 
  treemap(index= "Category",
          vSize="Users",
          type="index",
          title = "Users to the Arctic Data Center Site by Category (2016 to 2020)",
          palette = ADC_colors,
          fontsize.title = 16,
          fontsize.labels = 12,
          fontface.labels = 1,
          bg.labels = "#CCCCCCDC"
            ) 
  


### Make treemap interactive using d3treeR

# make it interactive ("rootname" becomes the title of the plot):
total_inter_cat_tree <- d3tree2(total_cat_user_tree,  rootname = "Users to the Arctic Data Center Site by Category (2016 to 2020)" )

total_inter_cat_tree




```



```{r Circular Bar Plot - Users/Categories/Year, echo = FALSE, warning = FALSE, message = FALSE, eval = FALSE}

#### Create a circular bar plot that visualizes colors by category and shows Users per Page


####### TEST WITH TOP 30 USERS 2016 ##########

top30_2016 <- transform(top30_2016, Category = as.character(Category),
                         Users = as.numeric(Users))

# Set a number of 'empty bar' to add at the end of each group
empty_bar <- 4
to_add <- data.frame( matrix(NA, empty_bar*nlevels(top30_2016$Category), ncol(top30_2016)) )
colnames(to_add) <- colnames(top30_2016)
to_add$Category <- rep(levels(top30_2016$Category), each=empty_bar)
top30_2016_p <- rbind(top30_2016, to_add)
top30_2016_p <- top30_2016_p %>% arrange(Category)
top30_2016_p$id <- seq(1, nrow(top30_2016_p))
 
# Get the name and the y position of each label
label_data <- top30_2016_p
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)
 
# Make the plot
plot_2016 <- ggplot(top30_2016_p, aes(x=as.factor(id), y=Users, fill=Category)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat="identity", alpha=0.5) +
  ylim(-100,120) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), "cm") 
  ) +
  coord_polar() + 
  geom_text(data=label_data, aes(x=id, y=Users+10, label=Page, hjust=hjust), color="black", fontface="bold",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE ) 
 
plot_2016


```
<br>
<br>

#### **Circular Bar Plot for Top 100 Users per Category in 2016**
```{r Circular Bar Plot by Category, echo = FALSE, warning = FALSE, message = FALSE}


### Try circular plot with Top 100 Users in 2016

top100_2016 <- head(sorted_2016, n = 100)

### PLOT ###

# Set a number of 'empty bar' to add at the end of each group
empty_bar <- 4
to_add <- data.frame( matrix(NA, empty_bar*nlevels(top100_2016$Category), ncol(top100_2016)) )
colnames(to_add) <- colnames(top100_2016)
to_add$Category <- rep(levels(top100_2016$Category), each=empty_bar)
top100_2016_p <- rbind(top100_2016, to_add)
top100_2016_p <- top100_2016_p %>% arrange(Category)
top100_2016_p$id <- seq(1, nrow(top100_2016_p))
 
# Get the name and the y position of each label
label_data <- top100_2016_p
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)
 
# Make the plot
plot_2016_100 <- ggplot(top100_2016_p, aes(x=as.factor(id), y=Users, fill=Category)) +       
  # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat="identity", alpha=0.5) +
  ylim(-100,120) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,10), "in") 
  ) +
  coord_polar() + 
  geom_text(data=label_data, aes(x=id, y=Users+10, label=Page, hjust=hjust), color="black", fontface="bold",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE ) 
 
plot_2016_100

#plot_2016_100 <- plot_2016_100 + theme_ADC()


```
<br>
<br>
<br>


#### **Circular Proportion Graph for Total Users by Category**
WORK IN PROGRESS
```{r Circular Proportion Graph, echo = TRUE, message = FALSE, warning = FALSE}

# Create circular graph that shoes proportion of users within each category (34 total categories)

circos.clear() 


category = annual_sortedDF$Category
percent = sort(sample(40:80, 34))
color = rev(rainbow(length(percent)))


circos.par("start.degree" = 90, cell.padding = c(0, 0, 0, 0),
           canvas.xlim=c(-1.2, 1.2),   # bigger canvas?
           canvas.ylim=c(-1.2, 1.2)) 
circos.initialize("a", xlim = c(0, 100)) # 'a` just means there is one sector
circos.track(ylim = c(1, length(percent)+1), track.height = 0.9, 
    bg.border = NA, panel.fun = function(x, y) {
        xlim = CELL_META$xlim
        circos.segments(rep(xlim[1], 34), 1:34,
                        rep(xlim[2], 34), 1:34,
                        col = "#CCCCCC")
        circos.rect(rep(0, 34), 1:34 - 0.45, percent, 1:34 + 0.45,
            col = color, border = "white")
        circos.text(rep(xlim[1], 34), 1:34, 
            paste(category, " - ", percent, "%"), 
            facing = "downward", adj = c(1.05, 0.5), cex = 0.8) 
        breaks = seq(0, 85, by = 5)
        circos.axis(h = "top", major.at = breaks, labels = paste0(breaks, "%"), 
            labels.cex = 0.6)
})


```

<br>
<br>


#### **Most Used Search Terms in Data Catalog**
```{r Search Terms 2020, echo = FALSE, message = FALSE, warning = FALSE}

## Create word clouds for most used search terms 
library(wordcloud2)



# read in data
searchwords_2020_raw <- read.csv("/home/t_hooper/ADC-Google-Analytics/searchwords_2020.csv")

# filter out users and unique events --> using "total events" as the word frequency for the word cloud
searchwords_2020 <- searchwords_2020_raw %>% 
  select(-users, -unique_events) 

# create word cloud
cloud_2020 <- wordcloud2(searchwords_2020, size=1.6, color = c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea"))

#cloud_2020

```

```{r Search Terms 2019, echo = FALSE, message = FALSE, warning = FALSE}

# read in data
searchwords_2019_raw <- read.csv("/home/t_hooper/ADC-Google-Analytics/searchwords_2019.csv")

# filter out users and unique events --> using "total events" as the word frequency for the word cloud
searchwords_2019 <- searchwords_2019_raw %>% 
  select(-users, -unique_events) %>% 
  rename(search_word = event_label)

# create word cloud
cloud_2019 <- wordcloud2(searchwords_2019, size=1.6, color = c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea"))

#cloud_2019

```

```{r Search Terms 2018, echo = FALSE, warning = FALSE, message = FALSE}

# read in data
searchwords_2018_raw <- read.csv("/home/t_hooper/ADC-Google-Analytics/searchwords_2018.csv")

# filter out users and unique events --> using "total events" as the word frequency for the word cloud
searchwords_2018 <- searchwords_2018_raw %>% 
  select(-users, -unique_events) %>% 
  rename(search_word = event_label)

# create word cloud
cloud_2018 <- wordcloud2(searchwords_2018, size=1.6, color = c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea"))

#cloud_2018


```

```{r Search Terms 2017, echo = FALSE, warning = FALSE, message = FALSE}

# read in data
searchwords_2017_raw <- read.csv("/home/t_hooper/ADC-Google-Analytics/searchwords_2017.csv")

# filter out users and unique events --> using "total events" as the word frequency for the word cloud
searchwords_2017 <- searchwords_2017_raw %>% 
  select(-users, -unique_events) %>% 
  rename(search_word = event_label)

# create word cloud
cloud_2017 <- wordcloud2(searchwords_2017, size=1.6, color = c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea"))

#cloud_2017

```


```{r Search Terms 2016, echo = FALSE, warning = FALSE, message= FALSE}

# read in data
searchwords_2016_raw <- read.csv("/home/t_hooper/ADC-Google-Analytics/searchwords_2016.csv")

# filter out users and unique events --> using "total events" as the word frequency for the word cloud
searchwords_2016 <- searchwords_2016_raw %>% 
  select(-users, -unique_events) %>% 
  rename(search_word = event_label)

# create word cloud
cloud_2016 <- wordcloud2(searchwords_2016, size=1.6, color = c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea"))

cloud_2016


```

```{r Top Search Terms of All Time, echo = FALSE, warning = FALSE, message = FALSE}

## Combine all years into one dataframe of search terms

searchwords_all <- rbind(searchwords_2016, searchwords_2017, searchwords_2018, searchwords_2019, searchwords_2020)

# take search terms that have been used 20 or more times
over_20_search <- searchwords_all %>% 
  filter(total_events >= 20)

# create word cloud for these terms
over_20_cloud <- wordcloud2(over_20_search, size=1.6, color = c("#146660", "#16897e", "#7afdb1", "#6dec65", "#1f254f", "#b5e5ea"))

over_20_cloud

```

<br>
<br>

#### **Top 10 Datasets Per Year**
```{r Top 10 Datasets Viewed, echo = FALSE, message = FALSE, warning = FALSE}

## Get top 50 datasets for 2016

datasets_2016 <- sorted_2016 %>% 
  filter(Category == "Dataset") %>% # filters out all rows within the Dataset category
  filter(grepl('view', Page)) %>% # filters out all catalog datasets 
  head(n = 10) %>% # take top 10 viewed datasets
  select(Page, Users, Pageviews, Year) # remove all columns except for thes 4

## NOTE that the hyphen patterns have been removed from the URL pathways. To get the correct URL for the clickable link go to Google Analytics. For some reason GA has removed the 'catalog/' from before the 'view/....' pathway. You will need to add 'catalog/' to the URL in order to get the correct page. 

# write.xlsx(datasets_2016, "/home/t_hooper/ADC-Google-Analytics/datasets_2016.xlsx")


## Get top 50 datasets for 2017

datasets_2017 <- sorted_2017 %>% 
  filter(Category == "Dataset") %>% # filters out all rows within the Dataset category
  filter(grepl('view', Page)) %>% # filters out all catalog datasets 
  head(n = 10) %>% # take top 10 viewed datasets
  select(Page, Users, Pageviews, Year) # remove all columns except for thes 4

# write.xlsx(datasets_2017, "/home/t_hooper/ADC-Google-Analytics/datasets_2017.xlsx")


## Get top 50 datasets for 2018

datasets_2018 <- sorted_2018 %>% 
  filter(Category == "Dataset") %>% # filters out all rows within the Dataset category
  filter(grepl('view', Page)) %>% # filters out all catalog datasets 
  head(n = 10) %>% # take top 10 viewed datasets
  select(Page, Users, Pageviews, Year) # remove all columns except for thes 4

# write.xlsx(datasets_2018, "/home/t_hooper/ADC-Google-Analytics/datasets_2018.xlsx")


## Get top 50 datasets for 2019

datasets_2019 <- sorted_2019 %>% 
  filter(Category == "Dataset") %>% # filters out all rows within the Dataset category
  filter(grepl('view', Page)) %>% # filters out all catalog datasets 
  head(n = 10) %>%  # take top 10 viewed datasets
  select(Page, Users, Pageviews, Year) # remove all columns except for these 4

# write.xlsx(datasets_2019, "/home/t_hooper/ADC-Google-Analytics/datasets_2019.xlsx")


## Get top 50 datasets for 2020

datasets_2020 <- sorted_2020 %>% 
  filter(Category == "Dataset") %>% # filters out all rows within the Dataset category
  filter(grepl('view', Page)) %>% # filters out all catalog datasets 
  head(n = 10) %>%  # take top 10 viewed datasets
  select(Page, Users, Pageviews, Year) # remove all columns except for thes 4

# write.xlsx(datasets_2020, "/home/t_hooper/ADC-Google-Analytics/datasets_2020.xlsx")


```


```{r Interactive Table for 2016 Datasets, echo = FALSE, warning = FALSE, message = FALSE}

### Add URL links to individual annual dataframes, then combine them into one dataframe for kable table

#### 2016 ####

# Transform columns to numeric so they are all aligned to the right
datasets_2016 <- transform(datasets_2016, Pageviews = as.numeric(Pageviews),
                         Year = as.numeric(Year))


# Add column for actual dataset name
datasets_2016$Dataset <- c("Collaborative Research: Toward a Circumarctic Lakes Observation Network (CALON)-- Multiscale observations of lacustrine systems.", "MAR v3.2 regional climate model data for Greenland (1958-2013).", "USGS Permafrost Temperatures Acquired from the DOI/GTN-P Deep Borehole Array in Arctic Alaska, 1973-continuing.", "The State of the Arctic Sea Ice Cover: Sustaining the integrated seasonal ice zone observing network.", "Collaborative Research: Sensitivity of Circum-Arctic Peatland Carbon to Holocene Warm Climates and Climate Seasonality.", "Nansen and Amundsen Basins Observational System.", "Arctic Shorebird Demographics Network.", "Passive acoustic data from A2 in the Bering Strait.", "Arctic Great Rivers Observatory.", "CTD and Mooring Data from the Eastern Eurasian and Makarov Basins, and Northern Laptev and East Siberian Seas from 2013-2015.")

# Reorder dataframe so that Dataset is first column, and remove pathway Page column
datasets_2016 <- datasets_2016[,c(5,2,3,4)]


# URLs for Top 10 Datasets
urls_16 <- c("https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85", "https://arcticdata.io/catalog/view/doi:10.5065/D6JH3J7Z", "https://arcticdata.io/catalog/view/doi:10.5065/D6N014HK", "https://arcticdata.io/catalog/view/urn:uuid:3fb067ab-a8c6-4297-863f-511f1d39233b", "https://arcticdata.io/catalog/view/urn:uuid:00edeb96-7444-41a8-9e73-59ac2893a497", "https://arcticdata.io/catalog/view/doi:10.18739/A23D20", "https://arcticdata.io/catalog/view/doi:10.18739/A2K89M", "https://arcticdata.io/catalog/view/arctic-data.1580.1", "https://arcticdata.io/catalog/view/urn:uuid:b9e1ee82-39d2-4219-b08d-0403d409e48d", "https://arcticdata.io/catalog/view/arctic-data.7792.15")

### Create table with embedded links for Dataset name 

datasets_2016_tbl <- datasets_2016 %>% 
  kbl(caption = "Top 10 Viewed Datasets Per Year", font = 14) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c("https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85", "https://arcticdata.io/catalog/view/doi:10.5065/D6JH3J7Z", "https://arcticdata.io/catalog/view/doi:10.5065/D6N014HK", "https://arcticdata.io/catalog/view/urn:uuid:3fb067ab-a8c6-4297-863f-511f1d39233b", "https://arcticdata.io/catalog/view/urn:uuid:00edeb96-7444-41a8-9e73-59ac2893a497", "https://arcticdata.io/catalog/view/doi:10.18739/A23D20", "https://arcticdata.io/catalog/view/doi:10.18739/A2K89M", "https://arcticdata.io/catalog/view/arctic-data.1580.1", "https://arcticdata.io/catalog/view/urn:uuid:b9e1ee82-39d2-4219-b08d-0403d409e48d", "https://arcticdata.io/catalog/view/arctic-data.7792.15")) # this line embeds the links within the text

#datasets_2016_tbl
  
```
 

```{r Interactive Table for 2017 Datasets, echo = FALSE, message = FALSE, warning = FALSE}

### Add URL links to individual annual dataframes, then combine them into one dataframe for kable table

## 2017 ##

# Transform columns to numeric so they are all aligned to the right
datasets_2017 <- transform(datasets_2017, Pageviews = as.numeric(Pageviews),
                         Year = as.numeric(Year))


# Add column for actual dataset name
datasets_2017$Dataset <- c("Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow density subdataset", "Collaborative Research: Toward a Circumarctic Lakes Observation Network (CALON)-- Multiscale observations of lacustrine systems.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow depth on sea ice subdataset.", "Nordenskioldland, Svalbard Reindeer Carbon and Nitrogen Isotope Data.", "USGS Permafrost Temperatures Acquired from the DOI/GTN-P Deep Borehole Array in Arctic Alaska, 1973-continuing." , "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) accumulation on land ice subdataset.", "Arctic Shorebird Demographics Network.", "Integrating Passive Acoustic Monitoring in long-term oceanographic observations of the Bering Strait.", "Automated ice mass balance site (SIZONET).", "NABOS - Water Quality and Physical Oceanography Data from the Eastern Eurasian and Makarov Basins, and Northern Laptev and East Siberian Seas in 2013.")

# Reorder dataframe so that Dataset is first column, and remove pathway Page column
datasets_2017 <- datasets_2017[,c(5,2,3,4)]


# URLs for Top 10 Datasets
urls_17 <- c("https://arcticdata.io/catalog/view/doi:10.18739/A2BJ96", "https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85", "https://arcticdata.io/catalog/view/doi:10.18739/A2W22P", "https://arcticdata.io/catalog/view/doi:10.18739/A27T10", "https://arcticdata.io/catalog/view/doi:10.5065/D6N014HK", "https://arcticdata.io/catalog/view/doi:10.18739/A2781G", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/urn:uuid:04adb1c7-d215-4c8f-9e80-79d56bc20bab", "https://arcticdata.io/catalog/view/doi:10.18739/A2D08X", "https://arcticdata.io/catalog/view/doi:10.18739/A2G95H")

### Create table with embedded links for Dataset name 

datasets_2017_tbl <- datasets_2017 %>% 
  kbl(caption = "Top 10 Viewed Datasets Per Year", font = 14) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c("https://arcticdata.io/catalog/view/doi:10.18739/A2BJ96", "https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85", "https://arcticdata.io/catalog/view/doi:10.18739/A2W22P", "https://arcticdata.io/catalog/view/doi:10.18739/A27T10", "https://arcticdata.io/catalog/view/doi:10.5065/D6N014HK", "https://arcticdata.io/catalog/view/doi:10.18739/A2781G", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/urn:uuid:04adb1c7-d215-4c8f-9e80-79d56bc20bab", "https://arcticdata.io/catalog/view/doi:10.18739/A2D08X", "https://arcticdata.io/catalog/view/doi:10.18739/A2G95H")) # this line embeds the links within the text

#datasets_2017_tbl


```


```{r Dataset Table for 2018, echo = FALSE, warning = FALSE, message = FALSE}


### Add URL links to individual annual dataframes, then combine them into one dataframe for kable table

## 2018 ##


## *** 2018 has a handful of datasets that are not compatible with ADC -- some are from the ESS-DIVE training and perhaps they copied the Google Analytics theme when making their own and so had redirected to the ADC site. Because these URL's don't work on ADC we need to filter them out 

datasets_2018 <- sorted_2018 %>% 
  filter(Category == "Dataset") %>% # filters out all rows within the Dataset category
  filter(!grepl('essdive', Page)) %>% # filters out all datasets that contain "view/ess-dive..."
  filter(!grepl('viewdoi103334', Page)) %>% #filters out all datasets from DOI:10.3334 
  filter(grepl('view', Page)) %>% # filters out all catalog datasets 
  head(n = 10) %>% # take top10 viewed datasets
  select(Page, Users, Pageviews, Year) # remove all columns except for these 4

# Transform columns to numeric so they are all aligned to the right
datasets_2018 <- transform(datasets_2018, Pageviews = as.numeric(Pageviews),
                         Year = as.numeric(Year))


# Add column for actual dataset name
datasets_2018$Dataset <- c("Photogrammetric scans of aerial photographs of North American glaciers.", " Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow depth on sea ice subdataset, Antarctica and Baltic Sea, 1990-2018.", "Soil bacterial community and functional shifts in response to altered snow pack in moist acidic tundra of Northern Alaska.", "A synthesis dataset of near-surface permafrost conditions for Alaska, 1997-2016.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow density subdataset, Greenland and Antartica, 1950-2018.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow depth on sea ice subdataset.", "Arctic Shorebird Demographics Network.", "Modle Atmosphrique Rgional (MAR) three-dimensional regional climate model (RCM), version 3.2, over Greenland, 1948-2016." , "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) accumulation on land ice subdataset, Greenland and Antarctica, 1987-2018.", "Floating and bedfast lake ice regimes across Arctic Alaska using space-borne SAR imagery from 1992-2016." )

# Reorder dataframe so that Dataset is first column, and remove pathway Page column
datasets_2018 <- datasets_2018[,c(5,2,3,4)]


# URLs for Top 10 Datasets
urls_18 <- c("https://arcticdata.io/catalog/view/doi:10.18739/A21R9G", "https://arcticdata.io/catalog/view/doi:10.18739/A2WS8HK6X", "https://arcticdata.io/catalog/view/doi:10.18739/A2556Q", "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A2W22P", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A2MV9S", "https://arcticdata.io/catalog/view/doi:10.18739/A2DR2P790", "https://arcticdata.io/catalog/view/doi:10.18739/A2FC5W")

### Create table with embedded links for Dataset name 

datasets_2018_tbl <- datasets_2018 %>% 
  kbl(caption = "Top 10 Viewed Datasets Per Year", font = 14) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c("https://arcticdata.io/catalog/view/doi:10.18739/A21R9G", "https://arcticdata.io/catalog/view/doi:10.18739/A2WS8HK6X", "https://arcticdata.io/catalog/view/doi:10.18739/A2556Q", "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A2W22P", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A2MV9S", "https://arcticdata.io/catalog/view/doi:10.18739/A2DR2P790", "https://arcticdata.io/catalog/view/doi:10.18739/A2FC5W")) # this line embeds the links within the text

#datasets_2018_tbl


```

```{r 2019 Datasets Table, echo = FALSE, warning = FALSE, message = FALSE }

### Add URL links to individual annual dataframes, then combine them into one dataframe for kable table

#### 2019 ####

# Transform columns to numeric so they are all aligned to the right
datasets_2019 <- transform(datasets_2019, Pageviews = as.numeric(Pageviews),
                         Year = as.numeric(Year))


# Add column for actual dataset name
datasets_2019$Dataset <- c("Estimating the Freshwater Flux from the Greenland Ice Sheet Workshop Report, American Geophysical Union, 2018.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow density subdataset, Greenland and Antartica, 1950-2018.", "Pacific arctic sea-ice observations from U.S. Federal logbooks (1900-1938).", "North Pole Environmental Observatory Bottle Chemistry. ", "Arctic Shorebird Demographics Network.", "Arctic Great Rivers Observatory III Biogeochemistry and Discharge Data, 2017-2019.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow density subdataset, Greenland and Antartica, 1950-2018.", "A synthesis dataset of near-surface permafrost conditions for Alaska, 1997-2016.", "Arctic Shorebird Demographics Network.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) accumulation on land ice subdataset, Greenland and Antarctica, 1987-2018.")

# Reorder dataframe so that Dataset is first column, and remove pathway Page column
datasets_2019 <- datasets_2019[,c(5,2,3,4)]


# URLs for Top 10 Datasets
urls_19 <- c("https://arcticdata.io/catalog/view/doi:10.18739/A24M9198B", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A21C1TF69", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S",  "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55",  "https://arcticdata.io/catalog/view/doi:10.18739/A28P5V92S", "https://arcticdata.io/catalog/view/doi:10.18739/A2DR2P790")

### Create table with embedded links for Dataset name 

datasets_2019_tbl <- datasets_2019 %>% 
  kbl(caption = "Top 10 Viewed Datasets Per Year", font = 14) %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c("https://arcticdata.io/catalog/view/doi:10.18739/A24M9198B", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A21C1TF69", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S",  "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55",  "https://arcticdata.io/catalog/view/doi:10.18739/A28P5V92S", "https://arcticdata.io/catalog/view/doi:10.18739/A2DR2P790" )) # this line embeds the links within the text

#datasets_2019_tbl


```

```{r 2020 Dataset Table, echo = FALSE, warning = FALSE, message = FALSE}

### Add URL links to individual annual dataframes, then combine them into one dataframe for kable table

#### 2020 ####

# Transform columns to numeric so they are all aligned to the right
datasets_2020 <- transform(datasets_2020, Pageviews = as.numeric(Pageviews),
                         Year = as.numeric(Year))


# Add column for actual dataset name
datasets_2020$Dataset <- c("Arc5km2018: Arctic Ocean Inverse Tide Model on a 5 kilometer grid, 2018.", "North Pole Environmental Observatory Bottle Chemistry.", "Global Seasonal Snow Classification System." , "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow density subdataset, Greenland and Antartica, 1950-2018.", "AOTIM5: Arctic Ocean Inverse Tide Model, on 5 kilometer grid, developed in 2004.", "Arctic Tidal Current Atlas from Moored Current Observations, Arctic Ocean, 1998-2018.", "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) accumulation on land ice subdataset, Greenland and Antarctica, 1987-2018.", " Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow depth on sea ice subdataset, Antarctica and Baltic Sea, 1990-2018.", " Pacific arctic sea-ice observations from U.S. Federal logbooks (1900-1938).",  "Surface Mass Balance and Snow Depth on Sea Ice Working Group (SUMup) snow density subdataset, Greenland and Antartica, 1950-2018.")

# Reorder dataframe so that Dataset is first column, and remove pathway Page column
datasets_2020 <- datasets_2020[,c(5,2,3,4)]


# URLs for Top 10 Datasets
urls_20 <- c("https://arcticdata.io/catalog/view/doi:10.18739/A21R6N14K", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.5065/D69G5JX5", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S", "https://arcticdata.io/catalog/view/doi:10.18739/A2S17SS80", "https://arcticdata.io/catalog/view/doi:10.18739/A26M3340D", "https://arcticdata.io/catalog/view/doi:10.18739/A2ZS2KD0Z", "https://arcticdata.io/catalog/view/doi:10.18739/A2222R601", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R" )

### Create table with embedded links for Dataset name 

datasets_2020_tbl <- datasets_2020 %>% 
  kbl(caption = "Top 10 Viewed Datasets Per Year") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c( "https://arcticdata.io/catalog/view/doi:10.18739/A21R6N14K", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.5065/D69G5JX5", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S", "https://arcticdata.io/catalog/view/doi:10.18739/A2S17SS80", "https://arcticdata.io/catalog/view/doi:10.18739/A26M3340D", "https://arcticdata.io/catalog/view/doi:10.18739/A2ZS2KD0Z", "https://arcticdata.io/catalog/view/doi:10.18739/A2222R601", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R")) # this line embeds the links within the text

#datasets_2020_tbl


```


```{r Combined Datasets 2016-2020 Table, echo = FALSE, warning = FALSE, message = FALSE}

# Combine top 10 datasets
topdatasets_16_20 <- rbind(datasets_2016, datasets_2017, datasets_2018, datasets_2019, datasets_2020)   


topdatasets_16_20 %>% 
  kbl(caption = "Top 10 Viewed Datasets Per Year") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c("https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85",  "https://arcticdata.io/catalog/view/doi:10.5065/D6JH3J7Z", "https://arcticdata.io/catalog/view/doi:10.5065/D6N014HK", "https://arcticdata.io/catalog/view/urn:uuid:3fb067ab-a8c6-4297-863f-511f1d39233b", "https://arcticdata.io/catalog/view/urn:uuid:00edeb96-7444-41a8-9e73-59ac2893a497", "https://arcticdata.io/catalog/view/doi:10.18739/A23D20", "https://arcticdata.io/catalog/view/doi:10.18739/A2K89M", "https://arcticdata.io/catalog/view/arctic-data.1580.1", "https://arcticdata.io/catalog/view/urn:uuid:b9e1ee82-39d2-4219-b08d-0403d409e48d", "https://arcticdata.io/catalog/view/arctic-data.7792.15", "https://arcticdata.io/catalog/view/doi:10.18739/A2BJ96", "https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85", "https://arcticdata.io/catalog/view/doi:10.18739/A2W22P", "https://arcticdata.io/catalog/view/doi:10.18739/A27T10", "https://arcticdata.io/catalog/view/doi:10.5065/D6N014HK", "https://arcticdata.io/catalog/view/doi:10.18739/A2781G", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/urn:uuid:04adb1c7-d215-4c8f-9e80-79d56bc20bab", "https://arcticdata.io/catalog/view/doi:10.18739/A2D08X", "https://arcticdata.io/catalog/view/doi:10.18739/A2G95H","https://arcticdata.io/catalog/view/doi:10.18739/A21R9G", "https://arcticdata.io/catalog/view/doi:10.18739/A2WS8HK6X", "https://arcticdata.io/catalog/view/doi:10.18739/A2556Q", "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A2W22P", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A2MV9S", "https://arcticdata.io/catalog/view/doi:10.18739/A2DR2P790", "https://arcticdata.io/catalog/view/doi:10.18739/A2FC5W", "https://arcticdata.io/catalog/view/doi:10.18739/A24M9198B", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A21C1TF69", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S",  "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55",  "https://arcticdata.io/catalog/view/doi:10.18739/A28P5V92S", "https://arcticdata.io/catalog/view/doi:10.18739/A2DR2P790", "https://arcticdata.io/catalog/view/doi:10.18739/A21R6N14K", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.5065/D69G5JX5", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S", "https://arcticdata.io/catalog/view/doi:10.18739/A2S17SS80", "https://arcticdata.io/catalog/view/doi:10.18739/A26M3340D", "https://arcticdata.io/catalog/view/doi:10.18739/A2ZS2KD0Z", "https://arcticdata.io/catalog/view/doi:10.18739/A2222R601", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R")) %>% 
  scroll_box(height = "400px")

```

<br>
<br>

#### **Top 20 Datasets of all Time**
```{r Top 10 Datasets, echo = FALSE, warning = FALSE, message = FALSE}

## Need to sort dataframe by Users
alltopdatasets <- topdatasets_16_20 %>% 
  arrange(desc(Users))

## Get top 20 datasets
top20datasets <- alltopdatasets %>% 
  head(n = 20)

## Create table for top datasets
top20datasets %>% 
  kbl(caption = "Top 20 Viewed Datasets of All Time") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, 
              link = c("https://arcticdata.io/catalog/view/doi:10.18739/A24M9198B", "https://arcticdata.io/catalog/view/doi:10.18739/A21R6N14K", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.18739/A20P0WQ7M", "https://arcticdata.io/catalog/view/doi:10.18739/A25T3FZ8X", "https://arcticdata.io/catalog/view/doi:10.5065/D69G5JX5", "https://arcticdata.io/catalog/view/doi:10.18739/A26D5PB2S", "https://arcticdata.io/catalog/view/doi:10.18739/A2S17SS80", "https://arcticdata.io/catalog/view/doi:10.18739/A21R9G", "https://arcticdata.io/catalog/view/urn:uuid:ef1feed0-9057-4afb-963e-03769a0b3e85", "https://arcticdata.io/catalog/view/doi:10.18739/A2BJ96", "https://arcticdata.io/catalog/view/doi:10.18739/A2CD5M", "https://arcticdata.io/catalog/view/doi:10.18739/A26M3340D", "https://arcticdata.io/catalog/view/doi:10.18739/A2WS8HK6X", "https://arcticdata.io/catalog/view/doi:10.18739/A2ZS2KD0Z", "https://arcticdata.io/catalog/view/doi:10.18739/A2556Q", "https://arcticdata.io/catalog/view/doi:10.18739/A2KG55", "https://arcticdata.io/catalog/view/doi:10.18739/A2222R601", "https://arcticdata.io/catalog/view/doi:10.18739/A2JH3D23R")) %>% 
  scroll_box(height = "400px")



```

